{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "import gym\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define policy network\n",
    "class policy_net(nn.Module):\n",
    "    def __init__(self, nS, nH, nA): # nS: state space size, nH: n. of neurons in hidden layer, nA: size action space\n",
    "        super(policy_net, self).__init__()\n",
    "        self.h = nn.Linear(nS, nH)\n",
    "        self.out = nn.Linear(nH, nA)\n",
    "\n",
    "    # define forward pass with one hidden layer with ReLU activation and sofmax after output layer\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.h(x))\n",
    "        x = F.softmax(self.out(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create environment\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "# instantiate the policy\n",
    "policy = policy_net(env.observation_space.shape[0], 20, env.action_space.n)\n",
    "# create an optimizer\n",
    "optimizer = torch.optim.Adam(policy.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:      1\tAvg. Return:  53.00\n",
      "Episode:      2\tAvg. Return:  47.50\n",
      "Episode:      3\tAvg. Return:  47.00\n",
      "Episode:      4\tAvg. Return:  44.25\n",
      "Episode:      5\tAvg. Return:  38.60\n",
      "Episode:      6\tAvg. Return:  36.50\n",
      "Episode:      7\tAvg. Return:  35.86\n",
      "Episode:      8\tAvg. Return:  33.25\n",
      "Episode:      9\tAvg. Return:  31.22\n",
      "Episode:     10\tAvg. Return:  30.00\n",
      "Episode:     11\tAvg. Return:  29.09\n",
      "Episode:     12\tAvg. Return:  30.75\n",
      "Episode:     13\tAvg. Return:  30.00\n",
      "Episode:     14\tAvg. Return:  30.29\n",
      "Episode:     15\tAvg. Return:  31.33\n",
      "Episode:     16\tAvg. Return:  30.81\n",
      "Episode:     17\tAvg. Return:  29.94\n",
      "Episode:     18\tAvg. Return:  30.33\n",
      "Episode:     19\tAvg. Return:  30.74\n",
      "Episode:     20\tAvg. Return:  30.75\n",
      "Episode:     21\tAvg. Return:  30.43\n",
      "Episode:     22\tAvg. Return:  30.45\n",
      "Episode:     23\tAvg. Return:  29.61\n",
      "Episode:     24\tAvg. Return:  29.42\n",
      "Episode:     25\tAvg. Return:  28.72\n",
      "Episode:     26\tAvg. Return:  28.15\n",
      "Episode:     27\tAvg. Return:  28.19\n",
      "Episode:     28\tAvg. Return:  27.89\n",
      "Episode:     29\tAvg. Return:  27.41\n",
      "Episode:     30\tAvg. Return:  27.03\n",
      "Episode:     31\tAvg. Return:  26.52\n",
      "Episode:     32\tAvg. Return:  26.25\n",
      "Episode:     33\tAvg. Return:  25.88\n",
      "Episode:     34\tAvg. Return:  25.88\n",
      "Episode:     35\tAvg. Return:  26.17\n",
      "Episode:     36\tAvg. Return:  26.33\n",
      "Episode:     37\tAvg. Return:  26.38\n",
      "Episode:     38\tAvg. Return:  26.95\n",
      "Episode:     39\tAvg. Return:  27.28\n",
      "Episode:     40\tAvg. Return:  27.23\n",
      "Episode:     41\tAvg. Return:  27.34\n",
      "Episode:     42\tAvg. Return:  27.33\n",
      "Episode:     43\tAvg. Return:  27.42\n",
      "Episode:     44\tAvg. Return:  27.66\n",
      "Episode:     45\tAvg. Return:  27.44\n",
      "Episode:     46\tAvg. Return:  27.89\n",
      "Episode:     47\tAvg. Return:  27.81\n",
      "Episode:     48\tAvg. Return:  28.38\n",
      "Episode:     49\tAvg. Return:  29.29\n",
      "Episode:     50\tAvg. Return:  29.32\n",
      "Episode:     51\tAvg. Return:  30.12\n",
      "Episode:     52\tAvg. Return:  29.71\n",
      "Episode:     53\tAvg. Return:  29.66\n",
      "Episode:     54\tAvg. Return:  29.48\n",
      "Episode:     55\tAvg. Return:  29.51\n",
      "Episode:     56\tAvg. Return:  29.16\n",
      "Episode:     57\tAvg. Return:  29.18\n",
      "Episode:     58\tAvg. Return:  28.88\n",
      "Episode:     59\tAvg. Return:  28.85\n",
      "Episode:     60\tAvg. Return:  28.98\n",
      "Episode:     61\tAvg. Return:  28.82\n",
      "Episode:     62\tAvg. Return:  28.63\n",
      "Episode:     63\tAvg. Return:  28.98\n",
      "Episode:     64\tAvg. Return:  29.09\n",
      "Episode:     65\tAvg. Return:  29.20\n",
      "Episode:     66\tAvg. Return:  29.02\n",
      "Episode:     67\tAvg. Return:  29.58\n",
      "Episode:     68\tAvg. Return:  29.37\n",
      "Episode:     69\tAvg. Return:  29.19\n",
      "Episode:     70\tAvg. Return:  30.07\n",
      "Episode:     71\tAvg. Return:  29.93\n",
      "Episode:     72\tAvg. Return:  29.74\n",
      "Episode:     73\tAvg. Return:  30.10\n",
      "Episode:     74\tAvg. Return:  30.09\n",
      "Episode:     75\tAvg. Return:  30.95\n",
      "Episode:     76\tAvg. Return:  31.03\n",
      "Episode:     77\tAvg. Return:  30.97\n",
      "Episode:     78\tAvg. Return:  31.83\n",
      "Episode:     79\tAvg. Return:  32.08\n",
      "Episode:     80\tAvg. Return:  31.96\n",
      "Episode:     81\tAvg. Return:  33.06\n",
      "Episode:     82\tAvg. Return:  32.91\n",
      "Episode:     83\tAvg. Return:  34.14\n",
      "Episode:     84\tAvg. Return:  34.10\n",
      "Episode:     85\tAvg. Return:  34.11\n",
      "Episode:     86\tAvg. Return:  34.62\n",
      "Episode:     87\tAvg. Return:  34.47\n",
      "Episode:     88\tAvg. Return:  34.61\n",
      "Episode:     89\tAvg. Return:  34.64\n",
      "Episode:     90\tAvg. Return:  35.03\n",
      "Episode:     91\tAvg. Return:  35.29\n",
      "Episode:     92\tAvg. Return:  35.00\n",
      "Episode:     93\tAvg. Return:  35.19\n",
      "Episode:     94\tAvg. Return:  35.10\n",
      "Episode:     95\tAvg. Return:  34.92\n",
      "Episode:     96\tAvg. Return:  34.69\n",
      "Episode:     97\tAvg. Return:  34.64\n",
      "Episode:     98\tAvg. Return:  34.57\n",
      "Episode:     99\tAvg. Return:  34.95\n",
      "Episode:    100\tAvg. Return:  35.04\n",
      "Episode:    101\tAvg. Return:  34.68\n",
      "Episode:    102\tAvg. Return:  34.50\n",
      "Episode:    103\tAvg. Return:  34.50\n",
      "Episode:    104\tAvg. Return:  34.52\n",
      "Episode:    105\tAvg. Return:  34.66\n",
      "Episode:    106\tAvg. Return:  34.62\n",
      "Episode:    107\tAvg. Return:  34.53\n",
      "Episode:    108\tAvg. Return:  34.70\n",
      "Episode:    109\tAvg. Return:  34.94\n",
      "Episode:    110\tAvg. Return:  34.92\n",
      "Episode:    111\tAvg. Return:  35.38\n",
      "Episode:    112\tAvg. Return:  35.13\n",
      "Episode:    113\tAvg. Return:  35.48\n",
      "Episode:    114\tAvg. Return:  35.71\n",
      "Episode:    115\tAvg. Return:  35.94\n",
      "Episode:    116\tAvg. Return:  36.40\n",
      "Episode:    117\tAvg. Return:  36.69\n",
      "Episode:    118\tAvg. Return:  36.85\n",
      "Episode:    119\tAvg. Return:  36.69\n",
      "Episode:    120\tAvg. Return:  36.49\n",
      "Episode:    121\tAvg. Return:  36.44\n",
      "Episode:    122\tAvg. Return:  36.48\n",
      "Episode:    123\tAvg. Return:  36.54\n",
      "Episode:    124\tAvg. Return:  36.51\n",
      "Episode:    125\tAvg. Return:  37.31\n",
      "Episode:    126\tAvg. Return:  37.54\n",
      "Episode:    127\tAvg. Return:  37.42\n",
      "Episode:    128\tAvg. Return:  37.36\n",
      "Episode:    129\tAvg. Return:  37.45\n",
      "Episode:    130\tAvg. Return:  37.58\n",
      "Episode:    131\tAvg. Return:  38.28\n",
      "Episode:    132\tAvg. Return:  38.27\n",
      "Episode:    133\tAvg. Return:  38.57\n",
      "Episode:    134\tAvg. Return:  38.84\n",
      "Episode:    135\tAvg. Return:  39.02\n",
      "Episode:    136\tAvg. Return:  38.96\n",
      "Episode:    137\tAvg. Return:  39.06\n",
      "Episode:    138\tAvg. Return:  38.97\n",
      "Episode:    139\tAvg. Return:  38.97\n",
      "Episode:    140\tAvg. Return:  39.24\n",
      "Episode:    141\tAvg. Return:  39.42\n",
      "Episode:    142\tAvg. Return:  39.64\n",
      "Episode:    143\tAvg. Return:  40.05\n",
      "Episode:    144\tAvg. Return:  40.64\n",
      "Episode:    145\tAvg. Return:  40.73\n",
      "Episode:    146\tAvg. Return:  40.90\n",
      "Episode:    147\tAvg. Return:  40.86\n",
      "Episode:    148\tAvg. Return:  40.66\n",
      "Episode:    149\tAvg. Return:  40.27\n",
      "Episode:    150\tAvg. Return:  41.43\n",
      "Episode:    151\tAvg. Return:  41.11\n",
      "Episode:    152\tAvg. Return:  41.16\n",
      "Episode:    153\tAvg. Return:  41.16\n",
      "Episode:    154\tAvg. Return:  41.29\n",
      "Episode:    155\tAvg. Return:  41.34\n",
      "Episode:    156\tAvg. Return:  41.82\n",
      "Episode:    157\tAvg. Return:  42.02\n",
      "Episode:    158\tAvg. Return:  42.48\n",
      "Episode:    159\tAvg. Return:  43.38\n",
      "Episode:    160\tAvg. Return:  43.60\n",
      "Episode:    161\tAvg. Return:  43.87\n",
      "Episode:    162\tAvg. Return:  43.97\n",
      "Episode:    163\tAvg. Return:  43.88\n",
      "Episode:    164\tAvg. Return:  44.18\n",
      "Episode:    165\tAvg. Return:  44.43\n",
      "Episode:    166\tAvg. Return:  44.67\n",
      "Episode:    167\tAvg. Return:  44.70\n",
      "Episode:    168\tAvg. Return:  45.16\n",
      "Episode:    169\tAvg. Return:  45.44\n",
      "Episode:    170\tAvg. Return:  44.95\n",
      "Episode:    171\tAvg. Return:  45.19\n",
      "Episode:    172\tAvg. Return:  46.18\n",
      "Episode:    173\tAvg. Return:  46.29\n",
      "Episode:    174\tAvg. Return:  46.55\n",
      "Episode:    175\tAvg. Return:  46.03\n",
      "Episode:    176\tAvg. Return:  45.81\n",
      "Episode:    177\tAvg. Return:  45.95\n",
      "Episode:    178\tAvg. Return:  45.39\n",
      "Episode:    179\tAvg. Return:  45.29\n",
      "Episode:    180\tAvg. Return:  45.23\n",
      "Episode:    181\tAvg. Return:  44.45\n",
      "Episode:    182\tAvg. Return:  44.83\n",
      "Episode:    183\tAvg. Return:  44.14\n",
      "Episode:    184\tAvg. Return:  44.41\n",
      "Episode:    185\tAvg. Return:  45.33\n",
      "Episode:    186\tAvg. Return:  45.02\n",
      "Episode:    187\tAvg. Return:  45.04\n",
      "Episode:    188\tAvg. Return:  44.78\n",
      "Episode:    189\tAvg. Return:  45.08\n",
      "Episode:    190\tAvg. Return:  45.23\n",
      "Episode:    191\tAvg. Return:  45.02\n",
      "Episode:    192\tAvg. Return:  45.24\n",
      "Episode:    193\tAvg. Return:  45.01\n",
      "Episode:    194\tAvg. Return:  45.96\n",
      "Episode:    195\tAvg. Return:  46.23\n",
      "Episode:    196\tAvg. Return:  46.88\n",
      "Episode:    197\tAvg. Return:  46.83\n",
      "Episode:    198\tAvg. Return:  46.90\n",
      "Episode:    199\tAvg. Return:  46.46\n",
      "Episode:    200\tAvg. Return:  46.31\n",
      "Episode:    201\tAvg. Return:  46.44\n",
      "Episode:    202\tAvg. Return:  46.45\n",
      "Episode:    203\tAvg. Return:  46.25\n",
      "Episode:    204\tAvg. Return:  46.22\n",
      "Episode:    205\tAvg. Return:  46.63\n",
      "Episode:    206\tAvg. Return:  46.77\n",
      "Episode:    207\tAvg. Return:  46.76\n",
      "Episode:    208\tAvg. Return:  47.05\n",
      "Episode:    209\tAvg. Return:  47.09\n",
      "Episode:    210\tAvg. Return:  47.31\n",
      "Episode:    211\tAvg. Return:  47.49\n",
      "Episode:    212\tAvg. Return:  47.59\n",
      "Episode:    213\tAvg. Return:  47.70\n",
      "Episode:    214\tAvg. Return:  47.35\n",
      "Episode:    215\tAvg. Return:  47.42\n",
      "Episode:    216\tAvg. Return:  47.47\n",
      "Episode:    217\tAvg. Return:  47.54\n",
      "Episode:    218\tAvg. Return:  47.92\n",
      "Episode:    219\tAvg. Return:  48.49\n",
      "Episode:    220\tAvg. Return:  49.26\n",
      "Episode:    221\tAvg. Return:  50.05\n",
      "Episode:    222\tAvg. Return:  50.16\n",
      "Episode:    223\tAvg. Return:  50.53\n",
      "Episode:    224\tAvg. Return:  51.03\n",
      "Episode:    225\tAvg. Return:  50.52\n",
      "Episode:    226\tAvg. Return:  50.37\n",
      "Episode:    227\tAvg. Return:  50.72\n",
      "Episode:    228\tAvg. Return:  51.36\n",
      "Episode:    229\tAvg. Return:  51.67\n",
      "Episode:    230\tAvg. Return:  51.83\n",
      "Episode:    231\tAvg. Return:  52.93\n",
      "Episode:    232\tAvg. Return:  53.16\n",
      "Episode:    233\tAvg. Return:  53.07\n",
      "Episode:    234\tAvg. Return:  53.36\n",
      "Episode:    235\tAvg. Return:  53.21\n",
      "Episode:    236\tAvg. Return:  53.32\n",
      "Episode:    237\tAvg. Return:  53.43\n",
      "Episode:    238\tAvg. Return:  53.25\n",
      "Episode:    239\tAvg. Return:  53.27\n",
      "Episode:    240\tAvg. Return:  53.18\n",
      "Episode:    241\tAvg. Return:  53.37\n",
      "Episode:    242\tAvg. Return:  53.79\n",
      "Episode:    243\tAvg. Return:  54.25\n",
      "Episode:    244\tAvg. Return:  54.07\n",
      "Episode:    245\tAvg. Return:  54.03\n",
      "Episode:    246\tAvg. Return:  53.80\n",
      "Episode:    247\tAvg. Return:  54.16\n",
      "Episode:    248\tAvg. Return:  54.09\n",
      "Episode:    249\tAvg. Return:  54.48\n",
      "Episode:    250\tAvg. Return:  53.71\n",
      "Episode:    251\tAvg. Return:  54.40\n",
      "Episode:    252\tAvg. Return:  54.82\n",
      "Episode:    253\tAvg. Return:  54.86\n",
      "Episode:    254\tAvg. Return:  55.17\n",
      "Episode:    255\tAvg. Return:  55.16\n",
      "Episode:    256\tAvg. Return:  55.27\n",
      "Episode:    257\tAvg. Return:  55.21\n",
      "Episode:    258\tAvg. Return:  55.36\n",
      "Episode:    259\tAvg. Return:  54.95\n",
      "Episode:    260\tAvg. Return:  55.01\n",
      "Episode:    261\tAvg. Return:  54.70\n",
      "Episode:    262\tAvg. Return:  54.82\n",
      "Episode:    263\tAvg. Return:  54.81\n",
      "Episode:    264\tAvg. Return:  54.75\n",
      "Episode:    265\tAvg. Return:  54.64\n",
      "Episode:    266\tAvg. Return:  55.14\n",
      "Episode:    267\tAvg. Return:  55.26\n",
      "Episode:    268\tAvg. Return:  55.29\n",
      "Episode:    269\tAvg. Return:  55.46\n",
      "Episode:    270\tAvg. Return:  55.62\n",
      "Episode:    271\tAvg. Return:  55.62\n",
      "Episode:    272\tAvg. Return:  55.51\n",
      "Episode:    273\tAvg. Return:  55.10\n",
      "Episode:    274\tAvg. Return:  55.10\n",
      "Episode:    275\tAvg. Return:  54.84\n",
      "Episode:    276\tAvg. Return:  55.34\n",
      "Episode:    277\tAvg. Return:  55.76\n",
      "Episode:    278\tAvg. Return:  55.67\n",
      "Episode:    279\tAvg. Return:  55.67\n",
      "Episode:    280\tAvg. Return:  56.39\n",
      "Episode:    281\tAvg. Return:  56.26\n",
      "Episode:    282\tAvg. Return:  56.56\n",
      "Episode:    283\tAvg. Return:  56.13\n",
      "Episode:    284\tAvg. Return:  56.16\n",
      "Episode:    285\tAvg. Return:  55.72\n",
      "Episode:    286\tAvg. Return:  55.96\n",
      "Episode:    287\tAvg. Return:  56.72\n",
      "Episode:    288\tAvg. Return:  56.80\n",
      "Episode:    289\tAvg. Return:  56.77\n",
      "Episode:    290\tAvg. Return:  56.08\n",
      "Episode:    291\tAvg. Return:  56.69\n",
      "Episode:    292\tAvg. Return:  56.96\n",
      "Episode:    293\tAvg. Return:  56.94\n",
      "Episode:    294\tAvg. Return:  57.49\n",
      "Episode:    295\tAvg. Return:  58.16\n",
      "Episode:    296\tAvg. Return:  58.23\n",
      "Episode:    297\tAvg. Return:  58.20\n",
      "Episode:    298\tAvg. Return:  58.52\n",
      "Episode:    299\tAvg. Return:  58.99\n",
      "Episode:    300\tAvg. Return:  59.41\n",
      "Episode:    301\tAvg. Return:  59.82\n",
      "Episode:    302\tAvg. Return:  59.88\n",
      "Episode:    303\tAvg. Return:  60.18\n",
      "Episode:    304\tAvg. Return:  60.76\n",
      "Episode:    305\tAvg. Return:  60.64\n",
      "Episode:    306\tAvg. Return:  61.01\n",
      "Episode:    307\tAvg. Return:  61.41\n",
      "Episode:    308\tAvg. Return:  61.33\n",
      "Episode:    309\tAvg. Return:  61.71\n",
      "Episode:    310\tAvg. Return:  61.43\n",
      "Episode:    311\tAvg. Return:  60.95\n",
      "Episode:    312\tAvg. Return:  61.54\n",
      "Episode:    313\tAvg. Return:  62.12\n",
      "Episode:    314\tAvg. Return:  62.15\n",
      "Episode:    315\tAvg. Return:  61.68\n",
      "Episode:    316\tAvg. Return:  61.64\n",
      "Episode:    317\tAvg. Return:  62.05\n",
      "Episode:    318\tAvg. Return:  62.11\n",
      "Episode:    319\tAvg. Return:  62.38\n",
      "Episode:    320\tAvg. Return:  61.95\n",
      "Episode:    321\tAvg. Return:  61.98\n",
      "Episode:    322\tAvg. Return:  62.97\n",
      "Episode:    323\tAvg. Return:  62.95\n",
      "Episode:    324\tAvg. Return:  62.95\n",
      "Episode:    325\tAvg. Return:  63.07\n",
      "Episode:    326\tAvg. Return:  63.46\n",
      "Episode:    327\tAvg. Return:  63.49\n",
      "Episode:    328\tAvg. Return:  63.19\n",
      "Episode:    329\tAvg. Return:  63.10\n",
      "Episode:    330\tAvg. Return:  63.35\n",
      "Episode:    331\tAvg. Return:  62.29\n",
      "Episode:    332\tAvg. Return:  62.82\n",
      "Episode:    333\tAvg. Return:  63.10\n",
      "Episode:    334\tAvg. Return:  64.50\n",
      "Episode:    335\tAvg. Return:  64.87\n",
      "Episode:    336\tAvg. Return:  65.78\n",
      "Episode:    337\tAvg. Return:  66.08\n",
      "Episode:    338\tAvg. Return:  66.66\n",
      "Episode:    339\tAvg. Return:  67.35\n",
      "Episode:    340\tAvg. Return:  68.00\n",
      "Episode:    341\tAvg. Return:  68.02\n",
      "Episode:    342\tAvg. Return:  67.50\n",
      "Episode:    343\tAvg. Return:  66.79\n",
      "Episode:    344\tAvg. Return:  66.31\n",
      "Episode:    345\tAvg. Return:  67.63\n",
      "Episode:    346\tAvg. Return:  68.10\n",
      "Episode:    347\tAvg. Return:  68.02\n",
      "Episode:    348\tAvg. Return:  68.44\n",
      "Episode:    349\tAvg. Return:  68.40\n",
      "Episode:    350\tAvg. Return:  68.57\n",
      "Episode:    351\tAvg. Return:  68.91\n",
      "Episode:    352\tAvg. Return:  68.88\n",
      "Episode:    353\tAvg. Return:  69.74\n",
      "Episode:    354\tAvg. Return:  70.02\n",
      "Episode:    355\tAvg. Return:  69.97\n",
      "Episode:    356\tAvg. Return:  71.07\n",
      "Episode:    357\tAvg. Return:  71.66\n",
      "Episode:    358\tAvg. Return:  71.55\n",
      "Episode:    359\tAvg. Return:  71.19\n",
      "Episode:    360\tAvg. Return:  70.74\n",
      "Episode:    361\tAvg. Return:  71.25\n",
      "Episode:    362\tAvg. Return:  71.44\n",
      "Episode:    363\tAvg. Return:  71.79\n",
      "Episode:    364\tAvg. Return:  71.44\n",
      "Episode:    365\tAvg. Return:  71.60\n",
      "Episode:    366\tAvg. Return:  71.88\n",
      "Episode:    367\tAvg. Return:  72.11\n",
      "Episode:    368\tAvg. Return:  72.15\n",
      "Episode:    369\tAvg. Return:  72.37\n",
      "Episode:    370\tAvg. Return:  73.04\n",
      "Episode:    371\tAvg. Return:  73.47\n",
      "Episode:    372\tAvg. Return:  73.12\n",
      "Episode:    373\tAvg. Return:  73.75\n",
      "Episode:    374\tAvg. Return:  73.55\n",
      "Episode:    375\tAvg. Return:  73.73\n",
      "Episode:    376\tAvg. Return:  74.37\n",
      "Episode:    377\tAvg. Return:  74.07\n",
      "Episode:    378\tAvg. Return:  74.32\n",
      "Episode:    379\tAvg. Return:  74.70\n",
      "Episode:    380\tAvg. Return:  74.51\n",
      "Episode:    381\tAvg. Return:  75.03\n",
      "Episode:    382\tAvg. Return:  75.50\n",
      "Episode:    383\tAvg. Return:  76.28\n",
      "Episode:    384\tAvg. Return:  76.15\n",
      "Episode:    385\tAvg. Return:  76.03\n",
      "Episode:    386\tAvg. Return:  75.92\n",
      "Episode:    387\tAvg. Return:  76.39\n",
      "Episode:    388\tAvg. Return:  76.86\n",
      "Episode:    389\tAvg. Return:  76.75\n",
      "Episode:    390\tAvg. Return:  77.16\n",
      "Episode:    391\tAvg. Return:  77.12\n",
      "Episode:    392\tAvg. Return:  76.85\n",
      "Episode:    393\tAvg. Return:  77.75\n",
      "Episode:    394\tAvg. Return:  76.68\n",
      "Episode:    395\tAvg. Return:  76.27\n",
      "Episode:    396\tAvg. Return:  75.70\n",
      "Episode:    397\tAvg. Return:  76.19\n",
      "Episode:    398\tAvg. Return:  77.34\n",
      "Episode:    399\tAvg. Return:  77.98\n",
      "Episode:    400\tAvg. Return:  77.64\n",
      "Episode:    401\tAvg. Return:  77.60\n",
      "Episode:    402\tAvg. Return:  77.76\n",
      "Episode:    403\tAvg. Return:  78.23\n",
      "Episode:    404\tAvg. Return:  78.00\n",
      "Episode:    405\tAvg. Return:  78.67\n",
      "Episode:    406\tAvg. Return:  79.14\n",
      "Episode:    407\tAvg. Return:  79.45\n",
      "Episode:    408\tAvg. Return:  79.46\n",
      "Episode:    409\tAvg. Return:  80.04\n",
      "Episode:    410\tAvg. Return:  80.91\n",
      "Episode:    411\tAvg. Return:  81.52\n",
      "Episode:    412\tAvg. Return:  81.73\n",
      "Episode:    413\tAvg. Return:  81.05\n",
      "Episode:    414\tAvg. Return:  81.77\n",
      "Episode:    415\tAvg. Return:  83.00\n",
      "Episode:    416\tAvg. Return:  84.09\n",
      "Episode:    417\tAvg. Return:  83.72\n",
      "Episode:    418\tAvg. Return:  83.71\n",
      "Episode:    419\tAvg. Return:  83.53\n",
      "Episode:    420\tAvg. Return:  83.24\n",
      "Episode:    421\tAvg. Return:  82.78\n",
      "Episode:    422\tAvg. Return:  83.69\n",
      "Episode:    423\tAvg. Return:  83.80\n",
      "Episode:    424\tAvg. Return:  83.72\n",
      "Episode:    425\tAvg. Return:  84.50\n",
      "Episode:    426\tAvg. Return:  84.24\n",
      "Episode:    427\tAvg. Return:  84.65\n",
      "Episode:    428\tAvg. Return:  85.30\n",
      "Episode:    429\tAvg. Return:  86.29\n",
      "Episode:    430\tAvg. Return:  85.89\n",
      "Episode:    431\tAvg. Return:  86.48\n",
      "Episode:    432\tAvg. Return:  86.65\n",
      "Episode:    433\tAvg. Return:  87.17\n",
      "Episode:    434\tAvg. Return:  85.10\n",
      "Episode:    435\tAvg. Return:  85.25\n",
      "Episode:    436\tAvg. Return:  86.60\n",
      "Episode:    437\tAvg. Return:  86.20\n",
      "Episode:    438\tAvg. Return:  88.17\n",
      "Episode:    439\tAvg. Return:  88.30\n",
      "Episode:    440\tAvg. Return:  87.94\n",
      "Episode:    441\tAvg. Return:  88.08\n",
      "Episode:    442\tAvg. Return:  89.64\n",
      "Episode:    443\tAvg. Return:  90.90\n",
      "Episode:    444\tAvg. Return:  93.33\n",
      "Episode:    445\tAvg. Return:  92.10\n",
      "Episode:    446\tAvg. Return:  92.49\n",
      "Episode:    447\tAvg. Return:  93.37\n",
      "Episode:    448\tAvg. Return:  93.08\n",
      "Episode:    449\tAvg. Return:  92.98\n",
      "Episode:    450\tAvg. Return:  92.58\n",
      "Episode:    451\tAvg. Return:  91.71\n",
      "Episode:    452\tAvg. Return:  92.53\n",
      "Episode:    453\tAvg. Return:  92.95\n",
      "Episode:    454\tAvg. Return:  94.40\n",
      "Episode:    455\tAvg. Return:  95.82\n",
      "Episode:    456\tAvg. Return:  94.66\n",
      "Episode:    457\tAvg. Return:  94.57\n",
      "Episode:    458\tAvg. Return:  94.57\n",
      "Episode:    459\tAvg. Return:  95.38\n",
      "Episode:    460\tAvg. Return:  96.69\n",
      "Episode:    461\tAvg. Return:  97.11\n",
      "Episode:    462\tAvg. Return:  97.98\n",
      "Episode:    463\tAvg. Return: 101.46\n",
      "Episode:    464\tAvg. Return: 102.08\n",
      "Episode:    465\tAvg. Return: 103.99\n",
      "Episode:    466\tAvg. Return: 104.77\n",
      "Episode:    467\tAvg. Return: 104.91\n",
      "Episode:    468\tAvg. Return: 105.49\n",
      "Episode:    469\tAvg. Return: 105.88\n",
      "Episode:    470\tAvg. Return: 106.76\n",
      "Episode:    471\tAvg. Return: 107.86\n",
      "Episode:    472\tAvg. Return: 109.32\n",
      "Episode:    473\tAvg. Return: 109.74\n",
      "Episode:    474\tAvg. Return: 110.44\n",
      "Episode:    475\tAvg. Return: 112.61\n",
      "Episode:    476\tAvg. Return: 112.17\n",
      "Episode:    477\tAvg. Return: 116.23\n",
      "Episode:    478\tAvg. Return: 116.52\n",
      "Episode:    479\tAvg. Return: 118.22\n",
      "Episode:    480\tAvg. Return: 118.59\n",
      "Episode:    481\tAvg. Return: 118.92\n",
      "Episode:    482\tAvg. Return: 119.31\n",
      "Episode:    483\tAvg. Return: 119.11\n",
      "Episode:    484\tAvg. Return: 120.38\n",
      "Episode:    485\tAvg. Return: 120.66\n",
      "Episode:    486\tAvg. Return: 120.81\n",
      "Episode:    487\tAvg. Return: 120.57\n",
      "Episode:    488\tAvg. Return: 121.28\n",
      "Episode:    489\tAvg. Return: 122.15\n",
      "Episode:    490\tAvg. Return: 124.27\n",
      "Episode:    491\tAvg. Return: 124.42\n",
      "Episode:    492\tAvg. Return: 124.69\n",
      "Episode:    493\tAvg. Return: 126.37\n",
      "Episode:    494\tAvg. Return: 126.47\n",
      "Episode:    495\tAvg. Return: 126.84\n",
      "Episode:    496\tAvg. Return: 127.18\n",
      "Episode:    497\tAvg. Return: 127.57\n",
      "Episode:    498\tAvg. Return: 127.17\n",
      "Episode:    499\tAvg. Return: 126.69\n",
      "Episode:    500\tAvg. Return: 127.88\n",
      "Episode:    501\tAvg. Return: 128.13\n",
      "Episode:    502\tAvg. Return: 128.22\n",
      "Episode:    503\tAvg. Return: 128.85\n",
      "Episode:    504\tAvg. Return: 132.77\n",
      "Episode:    505\tAvg. Return: 133.43\n",
      "Episode:    506\tAvg. Return: 133.92\n",
      "Episode:    507\tAvg. Return: 133.33\n",
      "Episode:    508\tAvg. Return: 133.26\n",
      "Episode:    509\tAvg. Return: 132.90\n",
      "Episode:    510\tAvg. Return: 133.36\n",
      "Episode:    511\tAvg. Return: 133.16\n",
      "Episode:    512\tAvg. Return: 134.58\n",
      "Episode:    513\tAvg. Return: 135.53\n",
      "Episode:    514\tAvg. Return: 137.17\n",
      "Episode:    515\tAvg. Return: 137.89\n",
      "Episode:    516\tAvg. Return: 138.21\n",
      "Episode:    517\tAvg. Return: 138.69\n",
      "Episode:    518\tAvg. Return: 138.32\n",
      "Episode:    519\tAvg. Return: 138.68\n",
      "Episode:    520\tAvg. Return: 139.70\n",
      "Episode:    521\tAvg. Return: 140.53\n",
      "Episode:    522\tAvg. Return: 139.53\n",
      "Episode:    523\tAvg. Return: 139.97\n",
      "Episode:    524\tAvg. Return: 140.33\n",
      "Episode:    525\tAvg. Return: 140.33\n",
      "Episode:    526\tAvg. Return: 143.79\n",
      "Episode:    527\tAvg. Return: 144.38\n",
      "Episode:    528\tAvg. Return: 144.77\n",
      "Episode:    529\tAvg. Return: 144.25\n",
      "Episode:    530\tAvg. Return: 145.01\n",
      "Episode:    531\tAvg. Return: 145.66\n",
      "Episode:    532\tAvg. Return: 146.13\n",
      "Episode:    533\tAvg. Return: 146.23\n",
      "Episode:    534\tAvg. Return: 146.50\n",
      "Episode:    535\tAvg. Return: 147.60\n",
      "Episode:    536\tAvg. Return: 148.44\n",
      "Episode:    537\tAvg. Return: 150.09\n",
      "Episode:    538\tAvg. Return: 147.91\n",
      "Episode:    539\tAvg. Return: 148.41\n",
      "Episode:    540\tAvg. Return: 150.84\n",
      "Episode:    541\tAvg. Return: 152.97\n",
      "Episode:    542\tAvg. Return: 154.14\n",
      "Episode:    543\tAvg. Return: 154.66\n",
      "Episode:    544\tAvg. Return: 152.36\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m     env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# print(state)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# calculate probabilities of taking each action\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# sample an action from that set of probs\u001b[39;00m\n\u001b[0;32m     21\u001b[0m sampler \u001b[38;5;241m=\u001b[39m Categorical(probs)\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\mlagents_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\mlagents_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m, in \u001b[0;36mpolicy_net.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 10\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     11\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout(x), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\mlagents_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\mlagents_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Pawel\\anaconda3\\envs\\mlagents_env\\lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initialize gamma and stats\n",
    "gamma=0.99\n",
    "n_episode = 1\n",
    "returns = deque(maxlen=100)\n",
    "render_rate = 100 # render every render_rate episodes\n",
    "while True:\n",
    "    rewards = []\n",
    "    actions = []\n",
    "    states  = []\n",
    "    # reset environment\n",
    "    state, _= env.reset()\n",
    "    while True:\n",
    "        # render episode every render_rate epsiodes\n",
    "        if n_episode%render_rate==0:\n",
    "            env.render()\n",
    "\n",
    "        # print(state)\n",
    "        # calculate probabilities of taking each action\n",
    "        probs = policy(torch.tensor(state).unsqueeze(0).float())\n",
    "        # sample an action from that set of probs\n",
    "        sampler = Categorical(probs)\n",
    "        action = sampler.sample()\n",
    "\n",
    "        # use that action in the environment\n",
    "        new_state, reward, done, _, info = env.step(action.item())\n",
    "        # store state, action and reward\n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "\n",
    "        state = new_state\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # preprocess rewards\n",
    "    rewards = np.array(rewards)\n",
    "    # calculate rewards to go for less variance\n",
    "    R = torch.tensor([np.sum(rewards[i:]*(gamma**np.array(range(i, len(rewards))))) for i in range(len(rewards))])\n",
    "    # or uncomment following line for normal rewards\n",
    "    #R = torch.sum(torch.tensor(rewards))\n",
    "\n",
    "    # preprocess states and actions\n",
    "    states = torch.tensor(states).float()\n",
    "    actions = torch.tensor(actions)\n",
    "\n",
    "    # calculate gradient\n",
    "    probs = policy(states)\n",
    "    sampler = Categorical(probs)\n",
    "    log_probs = -sampler.log_prob(actions)   # \"-\" because it was built to work with gradient descent, but we are using gradient ascent\n",
    "    pseudo_loss = torch.sum(log_probs * R) # loss that when differentiated with autograd gives the gradient of J(Î¸)\n",
    "    # update policy weights\n",
    "    optimizer.zero_grad()\n",
    "    pseudo_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # calculate average return and print it out\n",
    "    returns.append(np.sum(rewards))\n",
    "    print(\"Episode: {:6d}\\tAvg. Return: {:6.2f}\".format(n_episode, np.mean(returns)))\n",
    "    n_episode += 1\n",
    "\n",
    "# close environment\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
