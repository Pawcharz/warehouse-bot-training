{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "from torch import multiprocessing\n",
    "from torch import nn\n",
    "from tensordict.nn import TensorDictModule\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "from torch import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
    "\n",
    "device = (\n",
    "    torch.device(0)\n",
    "    if torch.cuda.is_available() and not is_fork\n",
    "    else torch.device(\"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load unity environment using `mlagents_envs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pawel\\anaconda3\\envs\\mlagents\\lib\\site-packages\\mlagents_envs\\environment.py:94: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  unity_communicator_version = StrictVersion(unity_com_ver)\n"
     ]
    }
   ],
   "source": [
    "from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "\n",
    "channel = EngineConfigurationChannel()\n",
    "env_path = \"C:/Users/Pawel/Documents/Unity_Project/warehouse-bot-training/environment_builds/test_env_simplified/Warehouse_Bot.exe\"\n",
    "\n",
    "from torchrl.envs import UnityMLAgentsEnv\n",
    "\n",
    "unity_env = UnityEnvironment(\n",
    "  file_name=env_path,\n",
    "  side_channels=[channel],\n",
    "  additional_args=[\"-batchmode\", \"-nographics\"]\n",
    ")\n",
    "channel.set_configuration_parameters(time_scale=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform environment from `mlagents` to `gymnasium`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "print(gym.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "from mlagents_envs.base_env import ActionTuple\n",
    "\n",
    "class UnityGymWrapper(gym.Env):\n",
    "    def __init__(self, unity_env, seed=None):\n",
    "        super().__init__()\n",
    "        self.unity_env = unity_env\n",
    "        self.unity_env.reset()\n",
    "        self.behavior_name = list(self.unity_env.behavior_specs.keys())[0]\n",
    "        self.spec = self.unity_env.behavior_specs[self.behavior_name]   \n",
    "        \n",
    "        # Define observation space (assuming visual input)\n",
    "        obs_shape = self.spec.observation_specs[0].shape\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=obs_shape, dtype=np.uint8) # ???\n",
    "        \n",
    "        # Define action space\n",
    "        if self.spec.action_spec.is_discrete():\n",
    "            self.action_space = spaces.Discrete(self.spec.action_spec.discrete_branches[0])\n",
    "\n",
    "        \n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.unity_env.reset()\n",
    "        decision_steps, _ = self.unity_env.get_steps(self.behavior_name)\n",
    "        obs = decision_steps.obs[0]  # Assuming single-agent scenario\n",
    "        return obs, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        action_tuple = ActionTuple()\n",
    "        \n",
    "        if self.spec.action_spec.is_discrete():\n",
    "            action_tuple.add_discrete(np.array(action).reshape(1, -1))\n",
    "        \n",
    "        self.unity_env.set_action_for_agent(self.behavior_name, 0, action_tuple)\n",
    "        self.unity_env.step()\n",
    "        \n",
    "        decision_steps, terminal_steps = self.unity_env.get_steps(self.behavior_name)\n",
    "\n",
    "        if 0 in terminal_steps:\n",
    "            obs = terminal_steps.obs[0]\n",
    "            reward = terminal_steps.reward[0]\n",
    "            \n",
    "            # terminated - Natural episode ending.\n",
    "            terminated = not terminal_steps.interrupted[0]\n",
    "            \n",
    "            # truncated - \"Whether the truncation condition outside the scope of the MDP is satisfied. Typically, this is a timelimit\"\n",
    "            # interrupted - \"The episode ended due to max steps or external termination, not because the episode ended naturally (failed/succeeded).\"\n",
    "            truncated = terminal_steps.interrupted[0]\n",
    "            \n",
    "            # terminated and truncated are mutually exclusive\n",
    "        else:\n",
    "            obs = decision_steps.obs[0]\n",
    "            reward = decision_steps.reward[0]\n",
    "            terminated = False\n",
    "            truncated = False\n",
    "        \n",
    "        return obs, reward, terminated, truncated, {}\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass  # Unity renders its own environment\n",
    "    \n",
    "    def close(self):\n",
    "        self.unity_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gymnasium_env = UnityGymWrapper(unity_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating stable_baselines3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines3.common.env_util import make_vec_env\n",
    "# from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "\n",
    "# env = make_vec_env(gymnasium_env, n_envs=8, vec_env_cls=SubprocVecEnv)\n",
    "# model = PPO(\"MlpPolicy\", env, device=\"cpu\")\n",
    "# model.learn(total_timesteps=25_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 245      |\n",
      "|    ep_rew_mean     | -110     |\n",
      "| time/              |          |\n",
      "|    fps             | 498      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 276          |\n",
      "|    ep_rew_mean          | -117         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 490          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040261084 |\n",
      "|    clip_fraction        | 0.0285       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.00179      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 95.3         |\n",
      "|    n_updates            | 6            |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    value_loss           | 373          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 293         |\n",
      "|    ep_rew_mean          | -121        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 490         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009669706 |\n",
      "|    clip_fraction        | 0.0597      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 143         |\n",
      "|    n_updates            | 12          |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    value_loss           | 284         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 337         |\n",
      "|    ep_rew_mean          | -125        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 490         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008734566 |\n",
      "|    clip_fraction        | 0.0513      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 18          |\n",
      "|    policy_gradient_loss | -0.00439    |\n",
      "|    value_loss           | 249         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | -117        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 490         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010513852 |\n",
      "|    clip_fraction        | 0.0622      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.0575      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 24          |\n",
      "|    policy_gradient_loss | -0.00397    |\n",
      "|    value_loss           | 232         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 370         |\n",
      "|    ep_rew_mean          | -118        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 489         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008886166 |\n",
      "|    clip_fraction        | 0.0468      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 178         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00238    |\n",
      "|    value_loss           | 257         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 379         |\n",
      "|    ep_rew_mean          | -106        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 489         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007611199 |\n",
      "|    clip_fraction        | 0.0497      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 36          |\n",
      "|    policy_gradient_loss | -0.00321    |\n",
      "|    value_loss           | 237         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 368          |\n",
      "|    ep_rew_mean          | -106         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 489          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 167          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065179295 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.303        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 87.2         |\n",
      "|    n_updates            | 42           |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    value_loss           | 223          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 334          |\n",
      "|    ep_rew_mean          | -80.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 489          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 188          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077938437 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.412        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 113          |\n",
      "|    n_updates            | 48           |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    value_loss           | 223          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 326         |\n",
      "|    ep_rew_mean          | -79.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 489         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 209         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005596289 |\n",
      "|    clip_fraction        | 0.0221      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 54          |\n",
      "|    policy_gradient_loss | -0.00319    |\n",
      "|    value_loss           | 210         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 320         |\n",
      "|    ep_rew_mean          | -66.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 489         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007849905 |\n",
      "|    clip_fraction        | 0.0367      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    value_loss           | 215         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 323          |\n",
      "|    ep_rew_mean          | -64.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 487          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 251          |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068024606 |\n",
      "|    clip_fraction        | 0.0365       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 72.4         |\n",
      "|    n_updates            | 66           |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    value_loss           | 214          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 309          |\n",
      "|    ep_rew_mean          | -45.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 487          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 273          |\n",
      "|    total_timesteps      | 133120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065509053 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 76.6         |\n",
      "|    n_updates            | 72           |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    value_loss           | 212          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 316         |\n",
      "|    ep_rew_mean          | -45.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 486         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006353891 |\n",
      "|    clip_fraction        | 0.0314      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.987      |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 99.5        |\n",
      "|    n_updates            | 78          |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    value_loss           | 212         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 323          |\n",
      "|    ep_rew_mean          | -44.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 486          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 315          |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054991394 |\n",
      "|    clip_fraction        | 0.0301       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.97        |\n",
      "|    explained_variance   | 0.609        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 103          |\n",
      "|    n_updates            | 84           |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    value_loss           | 167          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 317         |\n",
      "|    ep_rew_mean          | -23.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 485         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 337         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004523527 |\n",
      "|    clip_fraction        | 0.0331      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.972      |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0045     |\n",
      "|    value_loss           | 178         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 288          |\n",
      "|    ep_rew_mean          | 2.41         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 484          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 359          |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061061336 |\n",
      "|    clip_fraction        | 0.0484       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.949       |\n",
      "|    explained_variance   | 0.771        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 122          |\n",
      "|    n_updates            | 96           |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    value_loss           | 168          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 239         |\n",
      "|    ep_rew_mean          | 28.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 484         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 380         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004903661 |\n",
      "|    clip_fraction        | 0.0292      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.945      |\n",
      "|    explained_variance   | 0.818       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 91.3        |\n",
      "|    n_updates            | 102         |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 240         |\n",
      "|    ep_rew_mean          | 22          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 485         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 401         |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005435897 |\n",
      "|    clip_fraction        | 0.0209      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.893      |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 108         |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 250          |\n",
      "|    ep_rew_mean          | 28.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 485          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 421          |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032870744 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.927       |\n",
      "|    explained_variance   | 0.785        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 104          |\n",
      "|    n_updates            | 114          |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    value_loss           | 195          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 260         |\n",
      "|    ep_rew_mean          | 30          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 485         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 442         |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005551913 |\n",
      "|    clip_fraction        | 0.0508      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.906      |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.6        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 226          |\n",
      "|    ep_rew_mean          | 46.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 485          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 463          |\n",
      "|    total_timesteps      | 225280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044212127 |\n",
      "|    clip_fraction        | 0.0414       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.883       |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 52.3         |\n",
      "|    n_updates            | 126          |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 202         |\n",
      "|    ep_rew_mean          | 53.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 485         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 484         |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005322441 |\n",
      "|    clip_fraction        | 0.0522      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.862      |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.8        |\n",
      "|    n_updates            | 132         |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    value_loss           | 99.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 203          |\n",
      "|    ep_rew_mean          | 51.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 485          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 505          |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062688985 |\n",
      "|    clip_fraction        | 0.0398       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.848       |\n",
      "|    explained_variance   | 0.899        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 47.8         |\n",
      "|    n_updates            | 138          |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 208          |\n",
      "|    ep_rew_mean          | 50.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 485          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 526          |\n",
      "|    total_timesteps      | 256000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072026597 |\n",
      "|    clip_fraction        | 0.079        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.837       |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 27.7         |\n",
      "|    n_updates            | 144          |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    value_loss           | 99.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1f4d92b1c90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "model = PPO(\"MlpPolicy\", gymnasium_env, verbose=1,\n",
    "            learning_rate=3e-4,\n",
    "            n_steps=10240,\n",
    "            batch_size=256,\n",
    "            n_epochs=6,\n",
    "            clip_range=0.2,\n",
    "            gamma=0.99,\n",
    "            gae_lambda=0.96,\n",
    "            seed=0,\n",
    "            ent_coef=0.005,\n",
    "            vf_coef=0.5,\n",
    "            \n",
    "            \n",
    ")\n",
    "model.learn(total_timesteps=250_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./saved_models/test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
