{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "from torch import multiprocessing\n",
    "from torch import nn\n",
    "from tensordict.nn import TensorDictModule\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "from torch import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
    "\n",
    "device = (\n",
    "    torch.device(0)\n",
    "    if torch.cuda.is_available() and not is_fork\n",
    "    else torch.device(\"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load unity environment using `mlagents_envs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "\n",
    "channel = EngineConfigurationChannel()\n",
    "env_path = \"C:/Users/Pawel/Documents/Unity_Project/warehouse-bot-training/environment_builds/test_env_simplified/Warehouse_Bot.exe\"\n",
    "\n",
    "from torchrl.envs import UnityMLAgentsEnv\n",
    "\n",
    "unity_env = UnityEnvironment(\n",
    "  file_name=env_path,\n",
    "  side_channels=[channel],\n",
    "  # additional_args=[\"-batchmode\", \"-nographics\"]\n",
    ")\n",
    "channel.set_configuration_parameters(time_scale=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform environment from `mlagents` to `gymnasium`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gym.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "from mlagents_envs.base_env import ActionTuple\n",
    "\n",
    "class UnityGymWrapper(gym.Env):\n",
    "    def __init__(self, unity_env, seed=None):\n",
    "        super().__init__()\n",
    "        self.unity_env = unity_env\n",
    "        self.unity_env.reset()\n",
    "        self.behavior_name = list(self.unity_env.behavior_specs.keys())[0]\n",
    "        self.spec = self.unity_env.behavior_specs[self.behavior_name]   \n",
    "        \n",
    "        # Define observation space (assuming visual input)\n",
    "        obs_shape = self.spec.observation_specs[0].shape\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=obs_shape, dtype=np.uint8) # ???\n",
    "        \n",
    "        # Define action space\n",
    "        # if self.spec.action_spec.is_continuous():\n",
    "            # self.action_space = spaces.Box(\n",
    "            #     low=self.spec.action_spec.continuous_action_spec[0],\n",
    "            #     high=self.spec.action_spec.continuous_action_spec[1],\n",
    "            #     shape=(self.spec.action_spec.continuous_size,),\n",
    "            #     dtype=np.float32\n",
    "            # )\n",
    "        if self.spec.action_spec.is_discrete():\n",
    "            self.action_space = spaces.Discrete(self.spec.action_spec.discrete_branches[0])\n",
    "\n",
    "        \n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.unity_env.reset()\n",
    "        decision_steps, _ = self.unity_env.get_steps(self.behavior_name)\n",
    "        obs = decision_steps.obs[0]  # Assuming single-agent scenario\n",
    "        return obs, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        action_tuple = ActionTuple()\n",
    "        # if self.spec.action_spec.is_continuous():\n",
    "        #     action_tuple.add_continuous(np.array(action).reshape(1, -1))\n",
    "        # else:\n",
    "        #     action_tuple.add_discrete(np.array(action).reshape(1, -1))\n",
    "        \n",
    "        if self.spec.action_spec.is_discrete():\n",
    "            action_tuple.add_discrete(np.array(action).reshape(1, -1))\n",
    "        \n",
    "        # print(action_tuple, np.array(action).reshape(1, -1))\n",
    "        self.unity_env.set_action_for_agent(self.behavior_name, 0, action_tuple)\n",
    "        self.unity_env.step()\n",
    "        \n",
    "        decision_steps, terminal_steps = self.unity_env.get_steps(self.behavior_name)\n",
    "\n",
    "        if 0 in terminal_steps:\n",
    "            obs = terminal_steps.obs[0]\n",
    "            reward = terminal_steps.reward[0]\n",
    "            \n",
    "            # terminated - Natural episode ending.\n",
    "            terminated = not terminal_steps.interrupted[0]\n",
    "            \n",
    "            # truncated - \"Whether the truncation condition outside the scope of the MDP is satisfied. Typically, this is a timelimit\"\n",
    "            # interrupted - \"The episode ended due to max steps or external termination, not because the episode ended naturally (failed/succeeded).\"\n",
    "            truncated = terminal_steps.interrupted[0]\n",
    "            \n",
    "            # terminated and truncated are mutually exclusive\n",
    "        else:\n",
    "            obs = decision_steps.obs[0]\n",
    "            reward = decision_steps.reward[0]\n",
    "            terminated = False\n",
    "            truncated = False\n",
    "        \n",
    "        return obs, reward, terminated, truncated, {}\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass  # Unity renders its own environment\n",
    "    \n",
    "    def close(self):\n",
    "        self.unity_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gymnasium_env = UnityGymWrapper(unity_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gymnasium_env.step(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating stable_baselines3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "model = PPO(\"MlpPolicy\", gymnasium_env, verbose=1)\n",
    "model.learn(total_timesteps=100_000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
