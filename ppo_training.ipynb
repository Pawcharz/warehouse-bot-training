{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "from torch import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
    "\n",
    "device = (\n",
    "    torch.device(0)\n",
    "    if torch.cuda.is_available() and not is_fork\n",
    "    else torch.device(\"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load unity environment using `mlagents_envs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "\n",
    "channel = EngineConfigurationChannel()\n",
    "env_path = \"C:/Users/Pawel/Documents/Unity_Project/warehouse-bot-training/environment_builds/warehouse_step1_full/Warehouse_Bot.exe\"\n",
    "\n",
    "unity_env = UnityEnvironment(\n",
    "  file_name=env_path,\n",
    "  side_channels=[channel],\n",
    "  additional_args=[\"-batchmode\", \"-nographics\"]\n",
    ")\n",
    "channel.set_configuration_parameters(time_scale=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform environment from `mlagents` to `gymnasium`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "print(gym.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env_gymnasium_wrapper import UnityGymWrapper\n",
    "\n",
    "gymnasium_env = UnityGymWrapper(unity_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating stable_baselines3 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building onw network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "# # from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "# from stable_baselines3 import PPO\n",
    "\n",
    "# class CustomActorCriticPolicy(ActorCriticPolicy):\n",
    "#     def __init__(self, observation_space, action_space, lr_schedule, *args, **kwargs):\n",
    "#         super(CustomActorCriticPolicy, self).__init__(observation_space, action_space, lr_schedule, *args, **kwargs)\n",
    "\n",
    "#         print(self.features_extractor.features_dim, action_space)\n",
    "        \n",
    "#         # Define a custom shared feature extractor\n",
    "#         self.shared_net = nn.Sequential(\n",
    "#             nn.Linear(self.features_extractor.features_dim, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "        \n",
    "#         self.policy_net = nn.Sequential(\n",
    "#             nn.Linear(feature_dim, last_layer_dim_pi), nn.ReLU()\n",
    "#         )\n",
    "#         # Value network\n",
    "#         self.value_net = nn.Sequential(\n",
    "#             nn.Linear(feature_dim, last_layer_dim_vf), nn.ReLU()\n",
    "#         )\n",
    "\n",
    "#         print(f\"After override, value_net: {self.value_net}\")  # Debugging to check the size again\n",
    "\n",
    "#     def forward(self, obs, deterministic=False):\n",
    "#         features = self.extract_features(obs)\n",
    "#         print(f\"Extracted features shape: {features.shape}\")  # Check the extracted feature shape\n",
    "\n",
    "#         features = self.shared_net(features)\n",
    "#         print(f\"After shared_net, features shape: {features.shape}\")  # Should be (batch_size, 128)\n",
    "\n",
    "#         action_logits = self.policy_net(features)\n",
    "\n",
    "#         print(f\"Value net input shape (before passing to value_net): {features.shape}\")  # Must be (batch_size, 128)\n",
    "#         value = self.value_net(features)  # Should be fine if features.shape[1] == 128\n",
    "\n",
    "#         return action_logits, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://stable-baselines3.readthedocs.io/en/v1.0/guide/custom_policy.html\n",
    "\n",
    "# from typing import Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "\n",
    "# import torch as th\n",
    "# from torch import nn\n",
    "\n",
    "# from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "\n",
    "# class CustomNetwork(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Custom network for policy and value function.\n",
    "#     It receives as input the features extracted by the feature extractor.\n",
    "\n",
    "#     :param feature_dim: dimension of the features extracted with the features_extractor (e.g. features from a CNN)\n",
    "#     :param last_layer_dim_pi: (int) number of units for the last layer of the policy network\n",
    "#     :param last_layer_dim_vf: (int) number of units for the last layer of the value network\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         feature_dim: int,\n",
    "#         last_layer_dim_pi: int = 64,\n",
    "#         last_layer_dim_vf: int = 64,\n",
    "#     ):\n",
    "#         super(CustomNetwork, self).__init__()\n",
    "\n",
    "#         # IMPORTANT:\n",
    "#         # Save output dimensions, used to create the distributions\n",
    "#         self.latent_dim_pi = last_layer_dim_pi\n",
    "#         self.latent_dim_vf = last_layer_dim_vf\n",
    "\n",
    "#         # Policy network\n",
    "#         self.policy_net = nn.Sequential(\n",
    "#             nn.Linear(feature_dim, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, last_layer_dim_pi),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "#         # Value network\n",
    "#         self.value_net = nn.Sequential(\n",
    "#             nn.Linear(feature_dim, 64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(64, last_layer_dim_vf),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, features: th.Tensor) -> Tuple[th.Tensor, th.Tensor]:\n",
    "#         \"\"\"\n",
    "#         :return: (th.Tensor, th.Tensor) latent_policy, latent_value of the specified network.\n",
    "#             If all layers are shared, then ``latent_policy == latent_value``\n",
    "#         \"\"\"\n",
    "#         return self.policy_net(features), self.value_net(features)\n",
    "\n",
    "\n",
    "# class CustomActorCriticPolicy(ActorCriticPolicy):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         observation_space: gym.spaces.Space,\n",
    "#         action_space: gym.spaces.Space,\n",
    "#         lr_schedule: Callable[[float], float],\n",
    "#         net_arch: Optional[List[Union[int, Dict[str, List[int]]]]] = None,\n",
    "#         activation_fn: Type[nn.Module] = nn.Tanh,\n",
    "#         *args,\n",
    "#         **kwargs,\n",
    "#     ):\n",
    "\n",
    "#         super(CustomActorCriticPolicy, self).__init__(\n",
    "#             observation_space,\n",
    "#             action_space,\n",
    "#             lr_schedule,\n",
    "#             net_arch,\n",
    "#             activation_fn,\n",
    "#             # Pass remaining arguments to base class\n",
    "#             *args,\n",
    "#             **kwargs,\n",
    "#         )\n",
    "#         # Disable orthogonal initialization\n",
    "#         self.ortho_init = False\n",
    "\n",
    "#     def _build_mlp_extractor(self) -> None:\n",
    "#         self.mlp_extractor = CustomNetwork(self.features_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPO Hyperparams from mlagents-learn config file\n",
    "\n",
    "```yaml\n",
    "behaviors:\n",
    "  Dlivery_Bot_2:\n",
    "    trainer_type: ppo\n",
    "    hyperparameters:\n",
    "      batch_size: 512\n",
    "      buffer_size: 2560\n",
    "      learning_rate: 0.0003\n",
    "      beta: 0.005\n",
    "      epsilon: 0.2\n",
    "      lambd: 0.95\n",
    "      num_epoch: 3\n",
    "      learning_rate_schedule: linear\n",
    "    network_settings:\n",
    "      normalize: True\n",
    "      hidden_units: 256\n",
    "      num_layers: 2\n",
    "      vis_encode_type: simple\n",
    "    reward_signals:\n",
    "      extrinsic:\n",
    "        gamma: 0.99\n",
    "        strength: 1.0\n",
    "    keep_checkpoints: 5\n",
    "    checkpoint_interval: 100000\n",
    "    max_steps: 4000000\n",
    "    time_horizon: 1024\n",
    "    summary_freq: 10000\n",
    "    # threaded: False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Policy Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import torch.nn as nn\n",
    "\n",
    "model = PPO(\"MlpPolicy\", gymnasium_env, verbose=1,\n",
    "            learning_rate=3e-4,\n",
    "            n_steps=10240,\n",
    "            batch_size=512,\n",
    "            n_epochs=8,\n",
    "            clip_range=0.2,\n",
    "            gamma=0.995,\n",
    "            gae_lambda=0.96,\n",
    "            seed=0,\n",
    "            ent_coef=0.005,\n",
    "            vf_coef=0.5,\n",
    "            policy_kwargs={\n",
    "              \"net_arch\": [dict(pi=[128, 64], vf=[64, 32])],\n",
    "              \"activation_fn\": nn.ReLU\n",
    "            }\n",
    ")\n",
    "\n",
    "\n",
    "# model = PPO.load('./saved_models/warehouse_step1_full_1', gymnasium_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActorCriticPolicy(\n",
      "  (features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (pi_features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (vf_features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (mlp_extractor): MlpExtractor(\n",
      "    (policy_net): Sequential(\n",
      "      (0): Linear(in_features=100, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (value_net): Sequential(\n",
      "      (0): Linear(in_features=100, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (action_net): Linear(in_features=64, out_features=3, bias=True)\n",
      "  (value_net): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 68       |\n",
      "|    ep_rew_mean     | -144     |\n",
      "| time/              |          |\n",
      "|    fps             | 207      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 49       |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 90.8        |\n",
      "|    ep_rew_mean          | -175        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 206         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010099599 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.00145    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 461         |\n",
      "|    n_updates            | 8           |\n",
      "|    policy_gradient_loss | -0.00809    |\n",
      "|    value_loss           | 1.38e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 89.1        |\n",
      "|    ep_rew_mean          | -159        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 206         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005974229 |\n",
      "|    clip_fraction        | 0.0286      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.0647     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 182         |\n",
      "|    n_updates            | 16          |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    value_loss           | 518         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 85.5        |\n",
      "|    ep_rew_mean          | -144        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 206         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 198         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005164189 |\n",
      "|    clip_fraction        | 0.0258      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.029       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 265         |\n",
      "|    n_updates            | 24          |\n",
      "|    policy_gradient_loss | -0.00234    |\n",
      "|    value_loss           | 560         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 84.7       |\n",
      "|    ep_rew_mean          | -142       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 205        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 248        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00834547 |\n",
      "|    clip_fraction        | 0.0542     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.08      |\n",
      "|    explained_variance   | 0.0638     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 347        |\n",
      "|    n_updates            | 32         |\n",
      "|    policy_gradient_loss | -0.0035    |\n",
      "|    value_loss           | 682        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.3        |\n",
      "|    ep_rew_mean          | -118        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 206         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 298         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004622632 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.0411      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 352         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    value_loss           | 762         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 65.2        |\n",
      "|    ep_rew_mean          | -112        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 206         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 347         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003982873 |\n",
      "|    clip_fraction        | 0.0238      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 497         |\n",
      "|    n_updates            | 48          |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    value_loss           | 1.1e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 69           |\n",
      "|    ep_rew_mean          | -113         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 397          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047333306 |\n",
      "|    clip_fraction        | 0.0225       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.156        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 570          |\n",
      "|    n_updates            | 56           |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    value_loss           | 1.1e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 59.7        |\n",
      "|    ep_rew_mean          | -85.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 206         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 447         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004663152 |\n",
      "|    clip_fraction        | 0.0276      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 445         |\n",
      "|    n_updates            | 64          |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    value_loss           | 1.02e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64.9         |\n",
      "|    ep_rew_mean          | -86.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 496          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039051105 |\n",
      "|    clip_fraction        | 0.0352       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.968       |\n",
      "|    explained_variance   | 0.185        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 834          |\n",
      "|    n_updates            | 72           |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    value_loss           | 1.4e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 67           |\n",
      "|    ep_rew_mean          | -83.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 546          |\n",
      "|    total_timesteps      | 112640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051753223 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.95        |\n",
      "|    explained_variance   | 0.227        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 605          |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 68.9         |\n",
      "|    ep_rew_mean          | -90.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 596          |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039859866 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.921       |\n",
      "|    explained_variance   | 0.268        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 962          |\n",
      "|    n_updates            | 88           |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    value_loss           | 1.58e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 66.6        |\n",
      "|    ep_rew_mean          | -84.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 205         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 646         |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003910532 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.926      |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 687         |\n",
      "|    n_updates            | 96          |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    value_loss           | 1.47e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 70.2         |\n",
      "|    ep_rew_mean          | -78.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 696          |\n",
      "|    total_timesteps      | 143360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037975735 |\n",
      "|    clip_fraction        | 0.0225       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.913       |\n",
      "|    explained_variance   | 0.349        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 792          |\n",
      "|    n_updates            | 104          |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    value_loss           | 1.45e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 64.7        |\n",
      "|    ep_rew_mean          | -52.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 205         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 745         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005047695 |\n",
      "|    clip_fraction        | 0.0208      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.902      |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 687         |\n",
      "|    n_updates            | 112         |\n",
      "|    policy_gradient_loss | -0.00275    |\n",
      "|    value_loss           | 1.36e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73.3        |\n",
      "|    ep_rew_mean          | -86.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 205         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 795         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005388332 |\n",
      "|    clip_fraction        | 0.0287      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.898      |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 815         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00231    |\n",
      "|    value_loss           | 1.61e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 72.8         |\n",
      "|    ep_rew_mean          | -81.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 845          |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020494144 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.877       |\n",
      "|    explained_variance   | 0.373        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 635          |\n",
      "|    n_updates            | 128          |\n",
      "|    policy_gradient_loss | -0.00205     |\n",
      "|    value_loss           | 1.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 67.6         |\n",
      "|    ep_rew_mean          | -67.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 895          |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049847118 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.836       |\n",
      "|    explained_variance   | 0.394        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 661          |\n",
      "|    n_updates            | 136          |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    value_loss           | 1.5e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 65          |\n",
      "|    ep_rew_mean          | -61.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 205         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 945         |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004510837 |\n",
      "|    clip_fraction        | 0.0356      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.838      |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 690         |\n",
      "|    n_updates            | 144         |\n",
      "|    policy_gradient_loss | -0.00277    |\n",
      "|    value_loss           | 1.41e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 69.7         |\n",
      "|    ep_rew_mean          | -61.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 995          |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037958934 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.822       |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 731          |\n",
      "|    n_updates            | 152          |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68.8        |\n",
      "|    ep_rew_mean          | -60.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 205         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 1045        |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003406256 |\n",
      "|    clip_fraction        | 0.0276      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.811      |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 719         |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00271    |\n",
      "|    value_loss           | 1.48e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 62.7         |\n",
      "|    ep_rew_mean          | -53.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 1094         |\n",
      "|    total_timesteps      | 225280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035143779 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.785       |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 711          |\n",
      "|    n_updates            | 168          |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    value_loss           | 1.46e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 71.6         |\n",
      "|    ep_rew_mean          | -87.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 1144         |\n",
      "|    total_timesteps      | 235520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026666806 |\n",
      "|    clip_fraction        | 0.0235       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.776       |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 964          |\n",
      "|    n_updates            | 176          |\n",
      "|    policy_gradient_loss | -0.00188     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 63.1         |\n",
      "|    ep_rew_mean          | -52.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 1194         |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031258124 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.753       |\n",
      "|    explained_variance   | 0.402        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 763          |\n",
      "|    n_updates            | 184          |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    value_loss           | 1.51e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 67.7         |\n",
      "|    ep_rew_mean          | -66.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 1243         |\n",
      "|    total_timesteps      | 256000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021286127 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.733       |\n",
      "|    explained_variance   | 0.473        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 789          |\n",
      "|    n_updates            | 192          |\n",
      "|    policy_gradient_loss | -0.00133     |\n",
      "|    value_loss           | 1.54e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 66.4         |\n",
      "|    ep_rew_mean          | -69.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 1293         |\n",
      "|    total_timesteps      | 266240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026595164 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.746       |\n",
      "|    explained_variance   | 0.563        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 690          |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    value_loss           | 1.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 66.1         |\n",
      "|    ep_rew_mean          | -51.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 1343         |\n",
      "|    total_timesteps      | 276480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030972827 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.74        |\n",
      "|    explained_variance   | 0.588        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 750          |\n",
      "|    n_updates            | 208          |\n",
      "|    policy_gradient_loss | -0.00136     |\n",
      "|    value_loss           | 1.39e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 68.7         |\n",
      "|    ep_rew_mean          | -58.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 1393         |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026716958 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.707       |\n",
      "|    explained_variance   | 0.498        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 818          |\n",
      "|    n_updates            | 216          |\n",
      "|    policy_gradient_loss | -0.000977    |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 69.6         |\n",
      "|    ep_rew_mean          | -66.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 1442         |\n",
      "|    total_timesteps      | 296960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033010829 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.71        |\n",
      "|    explained_variance   | 0.465        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 811          |\n",
      "|    n_updates            | 224          |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 65.8        |\n",
      "|    ep_rew_mean          | -50.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 205         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 1492        |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004409823 |\n",
      "|    clip_fraction        | 0.0314      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.674      |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 793         |\n",
      "|    n_updates            | 232         |\n",
      "|    policy_gradient_loss | -0.00185    |\n",
      "|    value_loss           | 1.82e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 66.6         |\n",
      "|    ep_rew_mean          | -71.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 1542         |\n",
      "|    total_timesteps      | 317440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033506558 |\n",
      "|    clip_fraction        | 0.0281       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.637       |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 716          |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 70.7       |\n",
      "|    ep_rew_mean          | -77.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 205        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 1592       |\n",
      "|    total_timesteps      | 327680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00230917 |\n",
      "|    clip_fraction        | 0.0241     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.629     |\n",
      "|    explained_variance   | 0.512      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 759        |\n",
      "|    n_updates            | 248        |\n",
      "|    policy_gradient_loss | -0.00104   |\n",
      "|    value_loss           | 1.48e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 62.3         |\n",
      "|    ep_rew_mean          | -36.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 1641         |\n",
      "|    total_timesteps      | 337920       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028024253 |\n",
      "|    clip_fraction        | 0.0264       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.648       |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 765          |\n",
      "|    n_updates            | 256          |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 57.8         |\n",
      "|    ep_rew_mean          | -49.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 1691         |\n",
      "|    total_timesteps      | 348160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019290939 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.606       |\n",
      "|    explained_variance   | 0.581        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 777          |\n",
      "|    n_updates            | 264          |\n",
      "|    policy_gradient_loss | -0.0016      |\n",
      "|    value_loss           | 1.55e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 62.3         |\n",
      "|    ep_rew_mean          | -55          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 1741         |\n",
      "|    total_timesteps      | 358400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029775796 |\n",
      "|    clip_fraction        | 0.0251       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.585       |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 866          |\n",
      "|    n_updates            | 272          |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    value_loss           | 1.58e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 62.5         |\n",
      "|    ep_rew_mean          | -43.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 1790         |\n",
      "|    total_timesteps      | 368640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011368818 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.562       |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 757          |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.000955    |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.9         |\n",
      "|    ep_rew_mean          | -49.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 1840         |\n",
      "|    total_timesteps      | 378880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024546064 |\n",
      "|    clip_fraction        | 0.0307       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.554       |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 699          |\n",
      "|    n_updates            | 288          |\n",
      "|    policy_gradient_loss | -0.00127     |\n",
      "|    value_loss           | 1.52e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 64.8         |\n",
      "|    ep_rew_mean          | -45.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 1890         |\n",
      "|    total_timesteps      | 389120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026544263 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.577       |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 815          |\n",
      "|    n_updates            | 296          |\n",
      "|    policy_gradient_loss | -0.0012      |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 66.4         |\n",
      "|    ep_rew_mean          | -27.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 1939         |\n",
      "|    total_timesteps      | 399360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032667432 |\n",
      "|    clip_fraction        | 0.0235       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.562       |\n",
      "|    explained_variance   | 0.558        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 767          |\n",
      "|    n_updates            | 304          |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    value_loss           | 1.51e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 62.7         |\n",
      "|    ep_rew_mean          | -57.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 1989         |\n",
      "|    total_timesteps      | 409600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026310878 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.564       |\n",
      "|    explained_variance   | 0.542        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 872          |\n",
      "|    n_updates            | 312          |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 63.1         |\n",
      "|    ep_rew_mean          | -32.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 2039         |\n",
      "|    total_timesteps      | 419840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037122618 |\n",
      "|    clip_fraction        | 0.0351       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.566       |\n",
      "|    explained_variance   | 0.58         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 720          |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    value_loss           | 1.32e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 65.1        |\n",
      "|    ep_rew_mean          | -49.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 205         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 2089        |\n",
      "|    total_timesteps      | 430080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002692343 |\n",
      "|    clip_fraction        | 0.0315      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.552      |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 972         |\n",
      "|    n_updates            | 328         |\n",
      "|    policy_gradient_loss | -0.00236    |\n",
      "|    value_loss           | 1.85e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 62           |\n",
      "|    ep_rew_mean          | -49.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 2139         |\n",
      "|    total_timesteps      | 440320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019887574 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 811          |\n",
      "|    n_updates            | 336          |\n",
      "|    policy_gradient_loss | -0.000288    |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 57.6         |\n",
      "|    ep_rew_mean          | -30.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 2188         |\n",
      "|    total_timesteps      | 450560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014955396 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.535       |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 671          |\n",
      "|    n_updates            | 344          |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 61.1         |\n",
      "|    ep_rew_mean          | -37.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 2238         |\n",
      "|    total_timesteps      | 460800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016099712 |\n",
      "|    clip_fraction        | 0.00973      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.551       |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 766          |\n",
      "|    n_updates            | 352          |\n",
      "|    policy_gradient_loss | -0.00078     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 54.9         |\n",
      "|    ep_rew_mean          | -27.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 2288         |\n",
      "|    total_timesteps      | 471040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021754673 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.532       |\n",
      "|    explained_variance   | 0.562        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 807          |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 63.9       |\n",
      "|    ep_rew_mean          | -65.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 205        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 2337       |\n",
      "|    total_timesteps      | 481280     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00266958 |\n",
      "|    clip_fraction        | 0.0239     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.53      |\n",
      "|    explained_variance   | 0.545      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 840        |\n",
      "|    n_updates            | 368        |\n",
      "|    policy_gradient_loss | -0.0017    |\n",
      "|    value_loss           | 1.63e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 55.1         |\n",
      "|    ep_rew_mean          | -14.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 2387         |\n",
      "|    total_timesteps      | 491520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040223585 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.613        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 763          |\n",
      "|    n_updates            | 376          |\n",
      "|    policy_gradient_loss | -0.00205     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 58.3         |\n",
      "|    ep_rew_mean          | -36          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 2437         |\n",
      "|    total_timesteps      | 501760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022863536 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 722          |\n",
      "|    n_updates            | 384          |\n",
      "|    policy_gradient_loss | -0.00115     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x266c3bbb910>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=500_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./saved_models/warehouse_step1_full_2_2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
