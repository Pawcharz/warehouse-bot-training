{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "from torch import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
    "\n",
    "device = (\n",
    "    torch.device(0)\n",
    "    if torch.cuda.is_available() and not is_fork\n",
    "    else torch.device(\"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load unity environment using `mlagents_envs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "\n",
    "channel = EngineConfigurationChannel()\n",
    "env_path = \"D:/_Thesis/warehouse-bot-training/environment_builds/warehouse_stage2_find/Warehouse_Bot.exe\"\n",
    "\n",
    "unity_env = UnityEnvironment(\n",
    "  file_name=env_path,\n",
    "  side_channels=[channel],\n",
    "  additional_args=[\"-batchmode\", \"-nographics\"]\n",
    ")\n",
    "channel.set_configuration_parameters(time_scale=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform environment from `mlagents` to `gymnasium`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.1\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "print(gym.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env_camera_raycasts_gymnasium_wrapper import UnityCameraRaycastsGymWrapper\n",
    "\n",
    "gymnasium_env = UnityCameraRaycastsGymWrapper(unity_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating stable_baselines3 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building own network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPO Hyperparams from mlagents-learn config file\n",
    "\n",
    "```yaml\n",
    "behaviors:\n",
    "  Dlivery_Bot_2:\n",
    "    trainer_type: ppo\n",
    "    hyperparameters:\n",
    "      batch_size: 512\n",
    "      buffer_size: 2560\n",
    "      learning_rate: 0.0003\n",
    "      beta: 0.005\n",
    "      epsilon: 0.2\n",
    "      lambd: 0.95\n",
    "      num_epoch: 3\n",
    "      learning_rate_schedule: linear\n",
    "    network_settings:\n",
    "      normalize: True\n",
    "      hidden_units: 256\n",
    "      num_layers: 2\n",
    "      vis_encode_type: simple\n",
    "    reward_signals:\n",
    "      extrinsic:\n",
    "        gamma: 0.99\n",
    "        strength: 1.0\n",
    "    keep_checkpoints: 5\n",
    "    checkpoint_interval: 100000\n",
    "    max_steps: 4000000\n",
    "    time_horizon: 1024\n",
    "    summary_freq: 10000\n",
    "    # threaded: False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Policy Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "class CustomCombinedExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.spaces.Dict, features_dim: int = 256):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "\n",
    "        # Shapes of image and vector inputs: [<batch size>, <bands, height, width>], [<batch size>, <length>]\n",
    "        \n",
    "        # Create a sub-extractor for each modality\n",
    "        # For images of size: 3x36x64\n",
    "        self.image_net = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Compute output shape of CNN dynamically\n",
    "        with th.no_grad():\n",
    "            sample_image = th.as_tensor(observation_space.spaces[\"image\"].sample()[None]).float()\n",
    "            cnn_output_size = self.image_net(sample_image).shape[1]\n",
    "            \n",
    "        # Get size of the vector data dynamically\n",
    "        with th.no_grad():\n",
    "            vector_input_size = observation_space.spaces[\"vector\"].sample().shape[0]\n",
    "\n",
    "        self.vector_net = nn.Sequential(\n",
    "            nn.Linear(vector_input_size, 32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Get  output shape of the vector NN dynamically\n",
    "        with th.no_grad():\n",
    "            sample_vector = th.as_tensor(observation_space.spaces[\"vector\"].sample()).float()\n",
    "            vector_network_output_size = self.vector_net(sample_vector).shape[0]\n",
    "\n",
    "        # Final linear layer\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(cnn_output_size + vector_network_output_size, features_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, observations):\n",
    "        image = observations[\"image\"].float() / 255.0  # Normalize if needed\n",
    "        vector = observations[\"vector\"]\n",
    "\n",
    "        image_features = self.image_net(image)\n",
    "        vector_features = self.vector_net(vector)\n",
    "\n",
    "        combined = th.cat([image_features, vector_features], dim=1)\n",
    "        return self.linear(combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import torch.nn as nn\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomCombinedExtractor,\n",
    "    features_extractor_kwargs=dict(features_dim=32),\n",
    ")\n",
    "\n",
    "model = PPO(\"MultiInputPolicy\",\n",
    "            gymnasium_env, verbose=1,\n",
    "            learning_rate=3e-4,\n",
    "            n_steps=10240,\n",
    "            batch_size=512,\n",
    "            n_epochs=8,\n",
    "            clip_range=0.2,\n",
    "            gamma=0.995,\n",
    "            gae_lambda=0.96,\n",
    "            seed=0,\n",
    "            ent_coef=0.005,\n",
    "            vf_coef=0.5,\n",
    "            policy_kwargs=policy_kwargs,\n",
    "            tensorboard_log = './logs/stage2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83588\n",
      "<generator object Module.parameters at 0x000001DEFAC6E9D0>\n"
     ]
    }
   ],
   "source": [
    "print(get_n_params(model.policy))\n",
    "print(model.policy.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/stage2\\find_warehouse_1_spike_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 261      |\n",
      "|    ep_rew_mean     | -205     |\n",
      "| time/              |          |\n",
      "|    fps             | 114      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 89       |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 297         |\n",
      "|    ep_rew_mean          | -216        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 178         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012221684 |\n",
      "|    clip_fraction        | 0.0607      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.00207     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 188         |\n",
      "|    n_updates            | 8           |\n",
      "|    policy_gradient_loss | -0.00364    |\n",
      "|    value_loss           | 432         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 329         |\n",
      "|    ep_rew_mean          | -239        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012198052 |\n",
      "|    clip_fraction        | 0.0643      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -0.00102    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 227         |\n",
      "|    n_updates            | 16          |\n",
      "|    policy_gradient_loss | -0.00291    |\n",
      "|    value_loss           | 565         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 342         |\n",
      "|    ep_rew_mean          | -246        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 359         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013792994 |\n",
      "|    clip_fraction        | 0.0254      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 6.56e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 497         |\n",
      "|    n_updates            | 24          |\n",
      "|    policy_gradient_loss | -0.00183    |\n",
      "|    value_loss           | 982         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 385         |\n",
      "|    ep_rew_mean          | -283        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 450         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012273045 |\n",
      "|    clip_fraction        | 0.0389      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -1.32e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 228         |\n",
      "|    n_updates            | 32          |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    value_loss           | 543         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 409          |\n",
      "|    ep_rew_mean          | -308         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 541          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009416907 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | -1.67e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 377          |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.000299    |\n",
      "|    value_loss           | 950          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 394         |\n",
      "|    ep_rew_mean          | -285        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 632         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008725906 |\n",
      "|    clip_fraction        | 0.0429      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -4.77e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 403         |\n",
      "|    n_updates            | 48          |\n",
      "|    policy_gradient_loss | -0.00253    |\n",
      "|    value_loss           | 875         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 431         |\n",
      "|    ep_rew_mean          | -315        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 720         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008737339 |\n",
      "|    clip_fraction        | 0.0355      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -1.54e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 227         |\n",
      "|    n_updates            | 56          |\n",
      "|    policy_gradient_loss | -0.00175    |\n",
      "|    value_loss           | 470         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 432          |\n",
      "|    ep_rew_mean          | -311         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 113          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 812          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053746914 |\n",
      "|    clip_fraction        | 0.0285       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 1.61e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 454          |\n",
      "|    n_updates            | 64           |\n",
      "|    policy_gradient_loss | -0.00119     |\n",
      "|    value_loss           | 883          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 433         |\n",
      "|    ep_rew_mean          | -306        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 899         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008389344 |\n",
      "|    clip_fraction        | 0.0409      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 365         |\n",
      "|    n_updates            | 72          |\n",
      "|    policy_gradient_loss | -0.00253    |\n",
      "|    value_loss           | 689         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1defac4b700>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100_000, tb_log_name=\"find_warehouse_1_spike\", reset_num_timesteps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./saved_models/baselines/stage2/spike_1_100k.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
