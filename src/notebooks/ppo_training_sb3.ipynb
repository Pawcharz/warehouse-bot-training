{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "from torch import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
    "\n",
    "device = (\n",
    "    torch.device(0)\n",
    "    if torch.cuda.is_available() and not is_fork\n",
    "    else torch.device(\"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load unity environment using `mlagents_envs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform environment from `mlagents` to `gymnasium`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.1\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "print(gym.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from src.environments.env_camera_raycasts_gymnasium_wrapper import UnityCameraRaycastsGymWrapper\n",
    "\n",
    "env_path = \"D:/_Thesis/warehouse-bot-training/environment_builds/stage2/find_camera_raycasts_16x5/Warehouse_Bot.exe\"\n",
    "def make_env():\n",
    "\n",
    "  channel = EngineConfigurationChannel()\n",
    "\n",
    "  unity_env = UnityEnvironment(\n",
    "    file_name=env_path,\n",
    "    side_channels=[channel],\n",
    "    # additional_args=[\"-batchmode\", \"-nographics\"]\n",
    "  )\n",
    "  \n",
    "  channel.set_configuration_parameters(time_scale=1)\n",
    "  \n",
    "  gymnasium_env = UnityCameraRaycastsGymWrapper(unity_env)\n",
    "  gymnasium_env = Monitor(gymnasium_env)\n",
    "  \n",
    "  print(gymnasium_env.observation_space)\n",
    "  \n",
    "  return gymnasium_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict('image': Box(0, 255, (3, 36, 64), uint8), 'vector': Box(0.0, 255.0, (80,), float32))\n"
     ]
    }
   ],
   "source": [
    "env = DummyVecEnv([make_env])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating stable_baselines3 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Policy Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "      \n",
    "class CustomCombinedExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.spaces.Dict, image_channels=3, vector_obs_size=128, features_dim = 64):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "\n",
    "        # Shapes of image and vector inputs: [<batch size>, <bands, height, width>], [<batch size>, <length>]\n",
    "        \n",
    "        # Visual branch\n",
    "        self.visual_net = nn.Sequential(\n",
    "            nn.Conv2d(image_channels, 16, kernel_size=5, stride=4, padding=0),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        # Compute flattened visual output size from dummy input\n",
    "        dummy_input = torch.zeros(1, image_channels, 36, 64)\n",
    "        with torch.no_grad():\n",
    "            visual_out_size = self.visual_net(dummy_input).shape[1]\n",
    "\n",
    "        # Vector branch (raycast)\n",
    "        self.vector_net = nn.Sequential(\n",
    "            nn.Linear(vector_obs_size, 64),\n",
    "            Swish(),\n",
    "            nn.Linear(64, 64),                             \n",
    "            Swish()\n",
    "        )\n",
    "\n",
    "        # Combined MLP after concatenating visual + vector\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(visual_out_size + 64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, features_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, observations):\n",
    "        image = observations[\"visual\"].float()\n",
    "        vector = observations[\"vector\"]\n",
    "\n",
    "        image_features = self.visual_net(image)\n",
    "        vector_features = self.vector_net(vector)\n",
    "\n",
    "        # print(image_features.shape, vector_features.shape)\n",
    "        combined = th.cat([image_features, vector_features], dim=1)\n",
    "        return self.mlp(combined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decaying Entropy Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "class DecayingEntropyCalback(BaseCallback):\n",
    "    def __init__(self, initial_value=0.1, final_value=0.01, max_steps=100_000, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.initial_value = initial_value\n",
    "        self.final_value = final_value\n",
    "        self.max_steps = max_steps\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        progress = min(1.0, self.num_timesteps / self.max_steps)\n",
    "        current_ent_coef = self.initial_value * (1.0 - progress) + self.final_value * progress\n",
    "        self.model.ent_coef = current_ent_coef\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomCombinedExtractor,\n",
    "    features_extractor_kwargs=dict(image_channels=3, vector_obs_size=80, features_dim=32),\n",
    "    net_arch=[dict(pi=[32, 16], vf=[32, 16])],\n",
    "    activation_fn=nn.ReLU\n",
    ")\n",
    "\n",
    "model = PPO(\"MultiInputPolicy\",\n",
    "            env, verbose=1,\n",
    "            learning_rate=1e-3,\n",
    "            n_steps=1024,\n",
    "            batch_size=64,\n",
    "            n_epochs=4,\n",
    "            clip_range=0.2,\n",
    "            gamma=0.99,\n",
    "            gae_lambda=0.95,\n",
    "            seed=0,\n",
    "            ent_coef=0.1,\n",
    "            vf_coef=0.005,\n",
    "            policy_kwargs=policy_kwargs,\n",
    "            # stats_window_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90212\n"
     ]
    }
   ],
   "source": [
    "print(get_n_params(model.policy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 71.9     |\n",
      "|    ep_rew_mean     | -67.7    |\n",
      "| time/              |          |\n",
      "|    fps             | 44       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 1024     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 86.7        |\n",
      "|    ep_rew_mean          | -70         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008656893 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.00235    |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.845       |\n",
      "|    n_updates            | 4           |\n",
      "|    policy_gradient_loss | -0.00547    |\n",
      "|    value_loss           | 295         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 86.3         |\n",
      "|    ep_rew_mean          | -66.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 47           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 64           |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059434846 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.0566       |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.705        |\n",
      "|    n_updates            | 8            |\n",
      "|    policy_gradient_loss | -0.00113     |\n",
      "|    value_loss           | 198          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 96.6         |\n",
      "|    ep_rew_mean          | -67.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 47           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 86           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025605932 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.0578       |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 1.76         |\n",
      "|    n_updates            | 12           |\n",
      "|    policy_gradient_loss | -0.000957    |\n",
      "|    value_loss           | 234          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 107         |\n",
      "|    ep_rew_mean          | -61         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 47          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009633294 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.019       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.29        |\n",
      "|    n_updates            | 16          |\n",
      "|    policy_gradient_loss | -0.000891   |\n",
      "|    value_loss           | 195         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1c0f7e7dd80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decayingEntropyCallback = DecayingEntropyCalback(initial_value=0.02, final_value=0.005, max_steps=100_000)\n",
    "model.learn(total_timesteps=5_000, reset_num_timesteps=False, callback=decayingEntropyCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"saved_models/baselines/stage2/exemplary_camera_raycasts_5k\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
