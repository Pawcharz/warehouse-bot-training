{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
    "\n",
    "device = (\n",
    "    torch.device(0)\n",
    "    if torch.cuda.is_available() and not is_fork\n",
    "    else torch.device(\"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load unity environment using `mlagents_envs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "\n",
    "channel = EngineConfigurationChannel()\n",
    "env_path = \"D:/_Thesis/warehouse-bot-training/environment_builds/warehouse_stage2_find/Warehouse_Bot.exe\"\n",
    "\n",
    "unity_env = UnityEnvironment(\n",
    "  file_name=env_path,\n",
    "  side_channels=[channel],\n",
    "  # additional_args=[\"-batchmode\", \"-nographics\"]\n",
    ")\n",
    "channel.set_configuration_parameters(time_scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform environment from `mlagents` to `gymnasium`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.1\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "print(gym.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env_camera_raycasts_gymnasium_wrapper import UnityCameraRaycastsGymWrapper \n",
    "from env_raycasts_gymnasium_Wrapper import UnityRaycastsGymWrapper \n",
    "\n",
    "# gymnasium_env = UnityRaycastsGymWrapper(unity_env)\n",
    "gymnasium_env = UnityCameraRaycastsGymWrapper(unity_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating stable_baselines3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "model = PPO.load(\"./saved_models/baselines/stage2/find_1_500k\", gymnasium_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiInputActorCriticPolicy(\n",
      "  (features_extractor): CustomCombinedExtractor(\n",
      "    (image_enc_net): Sequential(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (7): ReLU(inplace=True)\n",
      "      (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (9): Flatten(start_dim=1, end_dim=-1)\n",
      "      (10): Linear(in_features=64, out_features=48, bias=True)\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): Linear(in_features=48, out_features=32, bias=True)\n",
      "      (13): ReLU(inplace=True)\n",
      "    )\n",
      "    (vector_enc_net): Sequential(\n",
      "      (0): Linear(in_features=60, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (linear): Sequential(\n",
      "      (0): Linear(in_features=48, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (pi_features_extractor): CustomCombinedExtractor(\n",
      "    (image_enc_net): Sequential(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (7): ReLU(inplace=True)\n",
      "      (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (9): Flatten(start_dim=1, end_dim=-1)\n",
      "      (10): Linear(in_features=64, out_features=48, bias=True)\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): Linear(in_features=48, out_features=32, bias=True)\n",
      "      (13): ReLU(inplace=True)\n",
      "    )\n",
      "    (vector_enc_net): Sequential(\n",
      "      (0): Linear(in_features=60, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (linear): Sequential(\n",
      "      (0): Linear(in_features=48, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (vf_features_extractor): CustomCombinedExtractor(\n",
      "    (image_enc_net): Sequential(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (7): ReLU(inplace=True)\n",
      "      (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (9): Flatten(start_dim=1, end_dim=-1)\n",
      "      (10): Linear(in_features=64, out_features=48, bias=True)\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): Linear(in_features=48, out_features=32, bias=True)\n",
      "      (13): ReLU(inplace=True)\n",
      "    )\n",
      "    (vector_enc_net): Sequential(\n",
      "      (0): Linear(in_features=60, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (linear): Sequential(\n",
      "      (0): Linear(in_features=48, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (mlp_extractor): MlpExtractor(\n",
      "    (policy_net): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=24, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (value_net): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (action_net): Linear(in_features=24, out_features=3, bias=True)\n",
      "  (value_net): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = model.get_env()\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for i in range(5000):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    # time.sleep(0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
