{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch as th\n",
    "from torch import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
    "\n",
    "device = (\n",
    "    th.device(0)\n",
    "    if th.cuda.is_available() and not is_fork\n",
    "    else th.device(\"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform environment from `mlagents` to `gymnasium`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "print(gym.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "from gymnasium.wrappers import NormalizeObservation, NormalizeReward\n",
    "\n",
    "from env_camera_raycasts_gymnasium_wrapper import UnityCameraRaycastsGymWrapper\n",
    "\n",
    "env_path = \"D:/_Thesis/warehouse-bot-training/environment_builds/warehouse_stage2_find/Warehouse_Bot.exe\"\n",
    "def make_env():\n",
    "\n",
    "  channel = EngineConfigurationChannel()\n",
    "\n",
    "  unity_env = UnityEnvironment(\n",
    "    file_name=env_path,\n",
    "    side_channels=[channel]\n",
    "    # no_graphics=True\n",
    "  )\n",
    "  \n",
    "  channel.set_configuration_parameters(time_scale=1)\n",
    "  \n",
    "  gymnasium_env = UnityCameraRaycastsGymWrapper(unity_env)\n",
    "  \n",
    "  # Add reward normalization\n",
    "  gymnasium_env = NormalizeReward(gymnasium_env)\n",
    "  \n",
    "  print(gymnasium_env.observation_space)\n",
    "  \n",
    "  return gymnasium_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Policy Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "# Actor-Critic Network\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim):\n",
    "        super().__init__()\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(obs_dim, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.policy_head = nn.Linear(64, act_dim)\n",
    "        self.value_head = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.shared(x)\n",
    "        return self.policy_head(x), self.value_head(x)\n",
    "\n",
    "    def get_action(self, obs):\n",
    "        logits, value = self.forward(obs)\n",
    "        dist = Categorical(logits=logits)\n",
    "        action = dist.sample()\n",
    "        return action, dist.log_prob(action), dist.entropy(), value.squeeze()\n",
    "\n",
    "    def evaluate_actions(self, obs, actions):\n",
    "        logits, values = self.forward(obs)\n",
    "        dist = Categorical(logits=logits)\n",
    "        log_probs = dist.log_prob(actions)\n",
    "        entropy = dist.entropy()\n",
    "        return log_probs, entropy, values.squeeze()\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * th.sigmoid(x)\n",
    "\n",
    "class ActorCriticMultimodal(nn.Module):\n",
    "    def __init__(self, act_dim, visual_size=[3, 36, 64], vector_obs_size=128):\n",
    "        super().__init__()\n",
    "        bands = visual_size[0]\n",
    "\n",
    "        # Shapes of image and vector inputs: [<batch size>, <bands, height, width>], [<batch size>, <length>]\n",
    "\n",
    "        visual_out_size = 64\n",
    "        vector_out_size = 32\n",
    "\n",
    "        # Visual Encoder\n",
    "        self.visual_encoder_cnn = nn.Sequential(\n",
    "            nn.Conv2d(bands, 16, kernel_size=5, stride=4, padding=0),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        # Compute flattened visual output size from dummy input\n",
    "        dummy_input = th.zeros(1, bands, visual_size[1], visual_size[2])\n",
    "        with th.no_grad():\n",
    "            visual_encoder_cnn_out_size = self.visual_encoder_cnn(dummy_input).shape[1]\n",
    "\n",
    "        self.visual_encoder_mlp = nn.Sequential(\n",
    "            nn.Linear(visual_encoder_cnn_out_size, 64),\n",
    "            Swish(),\n",
    "            nn.Linear(64, visual_out_size),\n",
    "            Swish()\n",
    "        )\n",
    "        \n",
    "        # Vector Encoder\n",
    "        self.vector_encoder = nn.Sequential(\n",
    "            nn.Linear(vector_obs_size, 32),\n",
    "            Swish(),\n",
    "            nn.Linear(32, vector_out_size),                             \n",
    "            Swish()\n",
    "        )\n",
    "\n",
    "        # Concatenation Network\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(visual_out_size + vector_out_size, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.policy_head = nn.Linear(32, act_dim)\n",
    "        self.value_head = nn.Linear(32, 1)\n",
    "\n",
    "    \n",
    "    def forward(self, observations):\n",
    "        image = observations[\"image\"].float()\n",
    "        vector = observations[\"vector\"]\n",
    "\n",
    "        image_features = self.visual_encoder_cnn(image)\n",
    "        image_features = self.visual_encoder_mlp(image_features)\n",
    "        vector_features = self.vector_encoder(vector)\n",
    "\n",
    "        combined = th.cat([image_features, vector_features], dim=1)\n",
    "        x = self.shared(combined)\n",
    "        return self.policy_head(x), self.value_head(x)\n",
    "\n",
    "    def get_action(self, obs):\n",
    "        logits, value = self.forward(obs)\n",
    "        dist = Categorical(logits=logits)\n",
    "        action = dist.sample()\n",
    "        return action, dist.log_prob(action), dist.entropy(), value.squeeze()\n",
    "\n",
    "    def evaluate_actions(self, obs, actions):\n",
    "        logits, values = self.forward(obs)\n",
    "        dist = Categorical(logits=logits)\n",
    "        log_probs = dist.log_prob(actions)\n",
    "        entropy = dist.entropy()\n",
    "        return log_probs, entropy, values.squeeze()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    Count parameters in each block of the network and total parameters.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing parameter counts for each block and total\n",
    "    \"\"\"\n",
    "    total_params = 0\n",
    "    block_params = {}\n",
    "    \n",
    "    for name, module in model.named_children():\n",
    "        params = sum(p.numel() for p in module.parameters())\n",
    "        block_params[name] = params\n",
    "        total_params += params\n",
    "        \n",
    "    block_params['total'] = total_params\n",
    "    return block_params\n",
    "\n",
    "# Example usage:\n",
    "# param_counts = count_parameters(model)\n",
    "# print(\"Parameter counts by block:\")\n",
    "# for block, count in param_counts.items():\n",
    "#     print(f\"{block}: {count:,} parameters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create settings dictionary\n",
    "settings = {\n",
    "    'gamma': 0.99,\n",
    "    'lam': 0.95,\n",
    "    'clip_eps': 0.2,\n",
    "    'ppo_epochs': 4,\n",
    "    'batch_size': 64,\n",
    "    'update_timesteps': 2048,\n",
    "    'lr': 1e-4,\n",
    "    'val_loss_coef': 0.5,\n",
    "    'ent_loss_coef':  0.01,\n",
    "    'device': th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment\n",
    "env = make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_dim = env.action_space.n\n",
    "\n",
    "# model_net_simple = ActorCritic(obs_dim, act_dim)\n",
    "# agent = PPOAgent(model_net_simple)\n",
    "model_net = ActorCriticMultimodal(act_dim, visual_size=[3, 36, 64], vector_obs_size=80)\n",
    "param_counts = count_parameters(model_net)\n",
    "print(param_counts)\n",
    "\n",
    "from PPO_algorithm import PPOAgent\n",
    "agent = PPOAgent(model_net, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.train(env, 25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
